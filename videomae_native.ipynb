{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataOLD import GODData\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import VideoMAEConfig, VideoMAEForVideoClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# better plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# better progress\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "# use GPU if available\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using GPU\")\n",
    "    device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "# train:   200\n",
      "# test:    50\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "print(\"Loading data...\")\n",
    "train_dataset = GODData(\n",
    "    subject=\"01\", \n",
    "    session_id=\"01\", \n",
    "    task=\"perception\", \n",
    "    train=True, \n",
    "    limit_size=200,\n",
    ")\n",
    "eval_dataset = GODData(\n",
    "    subject=\"01\", \n",
    "    session_id=\"01\", \n",
    "    task=\"perception\", \n",
    "    train=False, \n",
    "    limit_size=50,\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=8)\n",
    "\n",
    "print(f\"# train: {len(train_dataset):>5}\\n# test: {len(eval_dataset):>5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiating model...\n"
     ]
    }
   ],
   "source": [
    "# instantiate model\n",
    "print(\"Instantiating model...\")\n",
    "config = VideoMAEConfig(\n",
    "    image_size=64,\n",
    "    num_channels=3,\n",
    "    num_frames=50,\n",
    "    num_labels=150,\n",
    "    problem_type=\"single_label_classification\",\n",
    ")\n",
    "\n",
    "model = VideoMAEForVideoClassification(config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    accuracy = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for features, targets in dataloader:\n",
    "            batch = {}\n",
    "            batch[\"pixel_values\"] = torch.stack([f.permute(1, 0, 2, 3) for f in features]).to(device)\n",
    "            batch[\"labels\"] = targets.to(device)\n",
    "\n",
    "            print(batch[\"pixel_values\"][0].shape)\n",
    "\n",
    "            outputs = model(**batch)\n",
    "            predictions = np.argmax(outputs.logits.detach().cpu(), axis=-1)\n",
    "            print(predictions, targets)\n",
    "            accuracy += accuracy_score(targets.cpu(), predictions.cpu())\n",
    "\n",
    "    accuracy /= len(dataloader)\n",
    "\n",
    "    return {\"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, num_epochs, optimizer, eval_freq=10):\n",
    "    model.train()\n",
    "    loss_history = [] \n",
    "    metrics_history = []\n",
    "\n",
    "    pbar = trange(num_epochs)\n",
    "    for epoch in pbar:\n",
    "        loss_epoch = 0\n",
    "        for features, targets in dataloader:\n",
    "            batch = {}\n",
    "            batch[\"pixel_values\"] = torch.stack([f.permute(1, 0, 2, 3) for f in features]).to(device)\n",
    "            batch[\"labels\"] = targets.to(device)\n",
    "\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss_epoch += loss.item()\n",
    "\n",
    "        loss_epoch /= len(dataloader)\n",
    "\n",
    "        if epoch % eval_freq == 0:\n",
    "            loss_history.append(loss_epoch)\n",
    "            metrics_history.append(evaluate(model, eval_dataloader))\n",
    "            pbar.set_postfix(loss=f\"{loss_history[-1]:.4f}\", accuracy=f\"{metrics_history[-1]['accuracy']*100:.4f}%\")\n",
    "\n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1000\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3a794753bca45dc80535cfb335afb85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 3, 64, 64])\n",
      "tensor([106, 106, 106, 106, 106, 106, 106, 106]) tensor([34, 27, 39, 28, 12, 12, 42, 10])\n",
      "torch.Size([50, 3, 64, 64])\n",
      "tensor([106, 106, 106, 106, 106, 106, 106, 106]) tensor([40, 33, 11, 44,  6, 22,  2, 46])\n",
      "torch.Size([50, 3, 64, 64])\n",
      "tensor([106, 106, 106, 106, 106, 106, 106, 106]) tensor([15, 32, 49, 49, 14,  0,  4, 17])\n",
      "torch.Size([50, 3, 64, 64])\n",
      "tensor([106, 106, 106, 106, 106, 106, 106, 106]) tensor([17, 25, 13, 13, 18, 48, 48,  1])\n",
      "torch.Size([50, 3, 64, 64])\n",
      "tensor([106, 106, 106, 106, 106, 106, 106, 106]) tensor([35, 31, 29, 16,  9,  7, 45, 37])\n",
      "torch.Size([50, 3, 64, 64])\n",
      "tensor([106, 106, 106, 106, 106, 106, 106, 106]) tensor([47, 23,  5,  8, 38, 24, 26, 41])\n",
      "torch.Size([50, 3, 64, 64])\n",
      "tensor([106, 106]) tensor([20, 19])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loss_history \u001b[39m=\u001b[39m train(model, train_dataloader, num_epochs, optimizer)\n",
      "Cell \u001b[0;32mIn[7], line 16\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, num_epochs, optimizer, eval_freq)\u001b[0m\n\u001b[1;32m     14\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mbatch)\n\u001b[1;32m     15\u001b[0m loss \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mloss\n\u001b[0;32m---> 16\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     18\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     19\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/miniconda3/envs/v/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/v/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_history = train(model, train_dataloader, num_epochs, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
